{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python38264bitmyenvconda79347d8e286349d2b920a35841b643b7",
      "display_name": "Python 3.8.2 64-bit ('my_env': conda)"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDFpyeik6N3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import sys\n",
        "import pickle as pk\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouEBXD1uk6N8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "8334bd71-1517-40ea-cab0-9db4b7add7bf"
      },
      "source": [
        "workspace_dir = '.'\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount( '/content/drive/' )\n",
        "\n",
        "    workspace_dir = os.path.join( '.' , 'drive', 'My Drive', 'DIN-pytorch')\n",
        "    sys.path.append( workspace_dir)\n",
        "    ! rm -rf data\n",
        "    ! tar zxf \"{workspace_dir}/data.tar.gz\" -C ./\n",
        "    ! tar zxf \"{workspace_dir}/loader.tar.gz\" -C ./\n",
        "    ! ls -al data   \n",
        "except ImportError:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "EMQbWEQBk6N_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from model import DIN, DIEN, DynamicGRU\n",
        "from DataLoader import MyDataSet\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyIw70o-k6OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model hyper parameter\n",
        "MAX_LEN = 100\n",
        "EMBEDDING_DIM = 18\n",
        "# HIDDEN_SIZE_ATTENTION = [80, 40]\n",
        "# HIDDEN_SIZE_FC = [200, 80]\n",
        "# ACTIVATION_LAYER = 'LeakyReLU' # lr = 0.01\n",
        "\n",
        "\n",
        "# Adam\n",
        "LR = 1e-3\n",
        "BETA1 = 0.5\n",
        "BETA2 = 0.99\n",
        "\n",
        "# Train\n",
        "BATCH_SIZE = 128\n",
        "EPOCH_TIME = 20\n",
        "TEST_ITER = 1000\n",
        "\n",
        "RANDOM_SEED = 19940808\n",
        "\n",
        "USE_CUDA = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NQM5lkgk6OF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = os.path.join( './data', \"local_train_splitByUser\")\n",
        "test_file  = os.path.join( './data', \"local_test_splitByUser\")\n",
        "uid_voc    = os.path.join( './data', \"uid_voc.pkl\")\n",
        "mid_voc    = os.path.join( './data', \"mid_voc.pkl\")\n",
        "cat_voc    = os.path.join( './data', \"cat_voc.pkl\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "YnNy6DAqk6OH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if USE_CUDA and torch.cuda.is_available():\n",
        "    print( \"Cuda is avialable\" )\n",
        "    device = torch.device('cuda')\n",
        "    dtype = torch.cuda.FloatTensor\n",
        "else:\n",
        "    device = torch.device( 'cpu')\n",
        "    dtype = torch.FloatTensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC6I-EKmk6OK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stable the random seed\n",
        "def same_seeds(seed = RANDOM_SEED):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
        "    np.random.seed(seed)  \n",
        "    random.seed(seed) \n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Initilize  parameters\n",
        "def weights_init( m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_( m.bias.data, 0)\n",
        "    elif classname.find( 'BatchNorm') != -1:\n",
        "        nn.init.normal_( m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_( m.bias.data, 0)\n",
        "    elif classname.find( 'Linear') != -1:\n",
        "        nn.init.normal_( m.weight.data, 0.0, 0.02)\n",
        "\n",
        "\n",
        "def eval_output( scores, target, loss_function = torch.nn.functional.binary_cross_entropy_with_logits):\n",
        "    loss = loss_function( scores.type( dtype) , target.type( dtype))\n",
        "\n",
        "    y_pred = scores.sigmoid().round()\n",
        "    accuracy = ( y_pred == target).type( dtype).mean()\n",
        "\n",
        "    auc = roc_auc_score( target.cpu().detach(), scores.cpu().detach() )\n",
        "    return loss, accuracy, auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WajPHmvzk6ON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The dict mapping description(string) to type index(int) \n",
        "# A more graceful api https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder not used in this project\n",
        "\n",
        "user_map = pk.load( open( uid_voc, 'rb')); n_uid = len( user_map)\n",
        "material_map = pk.load( open( mid_voc, 'rb')); n_mid = len( material_map)\n",
        "category_map = pk.load( open( cat_voc, 'rb')); n_cat = len( category_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "D0dxFeCNk6OP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "same_seeds( RANDOM_SEED)\n",
        "\n",
        "dataset_train = MyDataSet( train_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
        "dataset_test = MyDataSet( test_file, user_map, material_map, category_map, max_length = MAX_LEN)\n",
        "\n",
        "loader_train = torch.utils.data.DataLoader( dataset_train, batch_size = BATCH_SIZE, shuffle = True)\n",
        "loader_test = torch.utils.data.DataLoader( dataset_test, batch_size = BATCH_SIZE, shuffle = False)\n",
        "\n",
        "# with open( 'loader.pkl', 'rb') as fin:\n",
        "#     loader_train, loader_test = pk.load(fin, encoding=\"bytes\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "2XTRK9jlk6OS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get model and initialize it\n",
        "# model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM).to( device)\n",
        "model = DIEN(  n_uid, n_mid, n_cat, EMBEDDING_DIM ).to( device)\n",
        "model.apply( weights_init)\n",
        "\n",
        "# Set loss function and optimizer\n",
        "optimizer = torch.optim.Adam( model.parameters(), LR, ( BETA1, BETA2))\n",
        "\n",
        "model.train(); iter = 0\n",
        "for epoch in range( EPOCH_TIME):\n",
        "\n",
        "    for i, data in enumerate( loader_train):\n",
        "        iter += 1\n",
        "\n",
        "        # transform data to target device\n",
        "        data = [ item.to( device) if item != None else None for item in data]\n",
        "        \n",
        "        target = data[-1]\n",
        "        \n",
        "        model.zero_grad()\n",
        "\n",
        "        scores = model( data, neg_sample = False)\n",
        "        \n",
        "        loss, accuracy, auc = eval_output( scores, target)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step( )\n",
        "        \n",
        "        print( \"\\r[%d/%d][%d/%d]\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( epoch + 1, EPOCH_TIME, i + 1, len( loader_train), loss.item(), accuracy.item(), auc.item() ) ,end='')\n",
        "\n",
        "        if iter % TEST_ITER == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                score_list = []; target_list = []\n",
        "                for data in  loader_test:\n",
        "                    data = [ item.to( device) if item != None else None for item in data]\n",
        "                    \n",
        "                    target = data[-1]\n",
        "                    \n",
        "                    scores = model( data, neg_sample = False)\n",
        "                    score_list.append( scores)\n",
        "                    target_list.append( target)\n",
        "                scores = torch.cat( score_list, dim = -1)\n",
        "                target = torch.cat( target_list, dim = -1)\n",
        "                loss, accuracy, auc = eval_output( scores, target)\n",
        "                print( \"\\tTest Set\\tloss:%.5f\\tacc:%.5f\\tauc:%.5f\"%( loss.item(), accuracy.item(), auc.item() ) )\n",
        "            model.train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}